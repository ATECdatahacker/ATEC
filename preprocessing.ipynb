{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading File\n",
    "\n",
    "### .npy file loading time:\n",
    "\n",
    "CPU times: user 23.7 s, sys: 39.5 s, total: 1min 3s\n",
    "Wall time: 2min 1s\n",
    "\n",
    "### .csv file loading time:\n",
    "\n",
    "CPU times: user 28 s, sys: 8.48 s, total: 36.5 s\n",
    "Wall time: 38.2 s\n",
    "\n",
    "### .h5 file loading time:\n",
    "CPU times: user 359 ms, sys: 2.39 s, total: 2.75 s\n",
    "Wall time: 4.23 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV file and restore them as .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.16 s, sys: 1.96 s, total: 4.12 s\n",
      "Wall time: 5.62 s\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/atec_anti_fraud_train.csv')\n",
    "%time df.to_hdf('data/0_data_train_', key='data', mode='w')\n",
    "df = pd.read_csv('data/atec_anti_fraud_test_a.csv')\n",
    "%time df.to_hdf('data/0_data_test_a_', key='data_test', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ = pd.read_hdf('data/0_data_train_')\n",
    "df_test_ = pd.read_hdf('data/0_data_test_a_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_['date'] = pd.to_datetime(df_train_['date'].astype('str'), format = '%Y%m%d')\n",
    "df_test_['date'] = pd.to_datetime(df_test_['date'].astype('str'), format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-05 00:00:00\n",
      "2018-01-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(df_train_['date'].max())\n",
    "print(df_test_['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with no NA are same for training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_noNA_ = df_train_.loc[:,df_train_.isnull().any(axis=0) == False]\n",
    "df_test_noNA_ = df_test_.loc[:,df_test_.isnull().any(axis=0) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear -1 label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_noNA_noMinusOne = df_train_noNA_[df_train_noNA_['label'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sort = df_train_noNA_noMinusOne.sort_values(by='date').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set split ratio as 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_rate = 0.7\n",
    "split_length = df_train_sort.shape[0]*split_rate\n",
    "\n",
    "df_train = df_train_sort.iloc[:int(split_length), :].reset_index(drop = True)\n",
    "df_test = df_train_sort.iloc[int(split_length):, :].reset_index(drop = True)\n",
    "\n",
    "X_train = df_train.drop(['label'], axis=1)\n",
    "y_train = df_train['label']\n",
    "X_test = df_test.drop(['label'], axis=1)\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_hdf('data/data_X_train', key='X_sub_train', mode='w')\n",
    "X_test.to_hdf('data/data_X_test', key='X_sub_test', mode='w')\n",
    "y_train.to_hdf('data/data_y_train', key='y_sub_train', mode='w')\n",
    "y_test.to_hdf('data/data_y_test', key='y_sub_test', mode='w')\n",
    "\n",
    "# Also store processed original training and test data\n",
    "df_train_noNA_noMinusOne.to_hdf('data/data_train_', key='train_', mode='w')\n",
    "df_test_noNA_.to_hdf('data/data_test_', key='test_', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Dummy test \n",
    "### Read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_hdf('data/data_X_train')\n",
    "X_test = pd.read_hdf('data/data_X_test')\n",
    "y_train = pd.read_hdf('data/data_y_train')\n",
    "y_test = pd.read_hdf('data/data_y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693004, 20) (693004,)\n",
      "(297002, 20) (297002,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clean NaN\n",
    "\n",
    "Every row contains at least 1 NaN.\n",
    "\n",
    "* Interpolate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Imbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "having risk:  0.0117117207684\n",
      "No risk:  0.983323543646\n",
      "No label:  0.0049647355851\n"
     ]
    }
   ],
   "source": [
    "print(\"having risk: \", np.sum(y_train == 1) / y_train.shape[0])\n",
    "print(\"No risk: \", np.sum(y_train == 0) / y_train.shape[0])\n",
    "print(\"No label: \", np.sum(y_train == -1) / y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
